{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 2. Четверг\n",
    "\n",
    "## Линейная регрессия"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ваша задача сегодня для лучшего понимания алгоритмов машинного обучения, реализовать свой класс Линейной регрессии на Python и `numpy` в частности.  \n",
    "\n",
    "* на _train_ выборке алгоритму необходиму оубчиться, на _test_ выборке проверить свой результат. Метрика для проверки результата для линейной регрессии - _MSE_, метрики реализовать внутри класса.\n",
    "\n",
    "* В качестве функции потерь, необходимо выбрать _MSE_ - для линейной регрессии. \n",
    "\n",
    "* Также необходиму пользователю Вашей модели предоставить возможность указать регуляризирующие коэффициенты и вид регуляризации('Ridge', 'Lasso', 'ElasticNet').  \n",
    "\n",
    "* При инициализации класса пользователь указывает вид регуляризации, и коэффициенты регуляризации. Если вид не указан регуляризация отсутствует  \n",
    "\n",
    "\n",
    "* После вы можете сравнить свой результат со стандартной Линейной регрессией, реализованной в _sklearn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подгрузите необходимые библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/UBkarima/1_Четверг_2//train_flats.csv')\n",
    "test = pd.read_csv('/home/UBkarima/1_Четверг_2//test_flats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __m2__ - площадь объекта (фича)\n",
    "* __dist__ - удаленность объекта от центра города(фича)\n",
    "* __price__ - цена (таргет)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Отнормируйте свои данные, используя [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Для линейных алгоритмов это очень важно  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(StandardScaler().fit_transform(train), columns=train.columns)\n",
    "test = pd.DataFrame(StandardScaler().fit_transform(test), columns=test.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSELoss = $\\dfrac{1}{N} \\sum_{i=1}^{N}(y_{act} - y_{pred})^2 = \\dfrac{1}{N} \\sum_{i=1}^{N}(y_{act} - (\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n))^2$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Возьмем функцию потерь на одном объекте"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L = (y_{act} - y_{pred})^2$  \n",
    "  \n",
    "$y_{act} - $ реальное значение, которое принимает наша величина\n",
    "\n",
    "$y_{pred} - $ значение, которое будет предсказывать наша модель\n",
    "\n",
    "\n",
    "Наше желание, чтобы модель, на каждом элементе выборки предсказывала значение как можно ближе к реальному\n",
    "\n",
    "* Как это сделать?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Посчитать для $L(\\vec{w}) = (y_{act} - (\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n))^2$ сложную частную производную по $w_1$.\n",
    "\n",
    "Как будет отличаться частная производная для $w_2, w_3, ..., w_n$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы знаем, что в случае линейной регрессии наше предсказание строится как  \n",
    "\n",
    "$y_{pred} = (\\omega_0 + x_{1} \\cdot \\omega_1 + x_{2} \\cdot \\omega_2 + ... + x_{n} \\cdot \\omega_n)$  \n",
    "\n",
    "$w_0, w_1, w_2, ..., w_n$ - Параметры, которые мы могли бы настроить!  \n",
    "\n",
    "Итоговая функция потерь на одном объекте:\n",
    "\n",
    "$L(\\vec{w}) = (y_{act} - (\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n))^2$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(\\vec{w})$ - сложная функция, которая состоит из следующих функциональных преобразований:  \n",
    "* возведения в квадрат\n",
    "* домножения наших $\\omega$ на константу - входные данные $x_1, x_2, ..., x_n$. Да да, именно они являются константами\n",
    "\n",
    "(_Смотреть выше расписанную формулу_)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Посчитать частную производную для $w_0$. (Свободного члена)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математически градиент готов, останется обернуть его в алгоритм градиентного спуска и на реальных данных, где у нас ни один объект, а много сразу.\n",
    "Единственной разницей того, что объектов много сразу, мы будем минимизировать функцию потерь в среднем на всех элементах.\n",
    "\n",
    "Формула для одного объекта была бы такой:\n",
    "    \n",
    "$\\vec{w_{new}} = \\vec{w_{old}} - lr * grad L(\\vec{w_{old}})$  \n",
    "\n",
    "Для всех объектов: \n",
    "\n",
    "1. Высчитывается градиент на каждом из ваших объектов(везде получаются разные $grad L(\\vec{w_{old}})$ - так как у каждого объекта свои $y, x_1, x_2, ...$).\n",
    "2. Берется средний $\\vec{\\omega_{old}}$ - по нему вычисляется новый $\\vec{w_{new}}$ у модели\n",
    "\n",
    "Итого:\n",
    "\n",
    "$\\vec{w_{new}} = \\vec{w_{old}} - lr * mean(grad L(\\vec{w_{old}}))$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создать класс LinReg. При инициализации дать возможность указать learning_rate, кол-во входных фичей(n). Записать эту информацию в атрибуты класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "    def __init__(self, learning_rate=0.01, n_inputs=1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_inputs=n_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создать случайную инициализцию необходимых $\\omega$ (Их будет n+1). Инициализируйте их равномерным распределением w1, w2, ..., wn = положите в атрибут - coef_, w0(свободный член) положите в атрибут intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "     def __init__(self, learning_rate, n_inputs):\n",
    "         self.learning_rate = learning_rate\n",
    "         self.n_inputs = n_inputs\n",
    "         self.coef_ = np.random.normal(-5,5,size=n_inputs)\n",
    "         self.intercept_ = np.random.normal(-5,5,size=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Опишите метод fit, который будет принимать на вход X, y (X - данные x1, x2, ..., xn, y - это $y_{act})$ и высчитывать с помощью градиентного спуска самые оптимальные параметры w0, w1, w2, ..., wn. Которые будут хранится в атрибутах coef_ и intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "     def __init__(self, learning_rate, n_inputs, epochs=10):\n",
    "         self.learning_rate = learning_rate\n",
    "         self.n_inputs = n_inputs\n",
    "         self.coef_ = np.random.normal(-5,5,size=n_inputs)\n",
    "         self.intercept_ = np.random.normal(-5,5,size=1)\n",
    "         self.epochs=epochs\n",
    "\n",
    "     def calc_grad(self,x,y):\n",
    "         y_pred = self.predict(X)\n",
    "         error = y-y_pred\n",
    "         grad_coef = (-2*X*error).mean(axis=0)     \n",
    "        \n",
    "     def fit(self, X, y):\n",
    "           X = np.array(X)# Переведем в numpy для матричных преобразований\n",
    "        y = np.array(y)\n",
    "        \n",
    "        self.coef_ = np.random.normal(size=X.shape[1]) # Инициализируем веса\n",
    "        self.intercept_ =  np.random.normal() # Инициализируем свободный член w0\n",
    "        \n",
    "        n_epochs = 100 # Я выберу 1000 Итераций\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            y_pred = self.intercept_ + X@self.coef_ \n",
    "            error = (y - y_pred)\n",
    "            w0_grad = -2 * error \n",
    "            w_grad = -2 * X * error.reshape(-1, 1) \n",
    "            self.coef_ = self.coef_ - self.learning_rate * w_grad.mean(axis=0) \n",
    "            self.intercept_ = self.intercept_ - self.learning_rate * w0_grad.mean() \n",
    "            \n",
    "            \n",
    "    def predict(self, X): #\n",
    "        X = np.array(X) \n",
    "        return X@self.coef_ + self.intercept_\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return r2_score(y, X@self.coef_ + self.intercept_) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Опишите метод predict, который будет предсказывать для новых точек в дальнейшем их y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ...\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Сравните результат с линейной регрессией в sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X, y)\n",
    "# lr.coef_, lr.intercept_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Напшите метод _score_. Который принимает данные _X_ и _y_  и высчитывает функционал качества, можно оставить тот же [MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error). Он нам понадобится для оценки качества работы алгоритмы на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ...\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         pass\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Посчитайте ваш _score_ и линейной регрессии из sklearn для тестового набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Нарисуйте 3D график, на котором будет следующее:\n",
    "\n",
    "* ось X и Y - [['m2', 'dist']]\n",
    "* ось Z -  price\n",
    "* через scatter все элементы выборки. Красными точками train, Синими test\n",
    "* Линейную плоскость предсказания"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10*. Добавьте возможность пользователю добавлять реугляризацию модели. Это не привносит больших изменений. Немного пмоеняется функция потерь и как следствие градиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs, reg_type='Ridge', alpha=0.2):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ...\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
